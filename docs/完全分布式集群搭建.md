## 0.总统概述

环境为：hadoop3.13+java8+centos7.5

完全分布式集群搭建最少需要3台服务器

集群规划如下：

|     hadoop01      |          hadoop02           |          hadoop03          |
| :---------------: | :-------------------------: | :------------------------: |
| NameNode/DataNode |          DataNode           | SecondaryNameNode/DataNode |
|    NodeManager    | ResourceManager/NodeManager |        NodeManager         |

## 1.配置环境

#### （1）安装虚拟机

centos7.5最小安装

克隆三台虚拟机

#### （2）修改克隆虚拟机的静态IP,

`sudo vim /etc/sysconfig/network-scripts/ifcfg-ens33`

```shell
#hadoop01

DEVICE=ens33
TYPE=Ethernet
ONBOOT=yes
BOOTPROTO=static
NAME="ens33"
IPADDR=192.168.1.101 #haodoop02为102，hadoop03为103
PREFIX=24
GATEWAY=192.168.1.2
DNS1=192.168.1.2
```

#### （3）修改主机名

`sudo hostnamectl --static set-hostname hadoop01`

#### （4）配置主机映射

`sudo vim /etc/hosts`

```shell
192.168.1.102 hadoop01
192.168.1.103 hadoop02
192.168.1.104 hadoop03
```

#### （5）关闭防火墙

```shell
sudo systemctl stop firewalld
sudo systemctl disable firewalld
```

#### （6）创建普通用户

```shell
sudo useradd bigdata #用户名为bigdata
sudo passwd bigdata #密码为bigdata
```

#### （7）配置bigdata用户具有root权限

`visudo`

```shell
## Allow root to run any commands anywhere
root    ALL=(ALL)     ALL
#配置为不输入密码
bigdata   ALL=(ALL)     NOPASSWD:ALL 

```

#### （8）安装一些依赖

```shell
 sudo yum install -y epel-release psmisc nc net-tools rsync vim lrzsz ntp libzstd openssl-static tree iotop git

```

#### （9）编写群发脚步rsync脚本

以某培训机构的编写的rsync脚本为例

```shell
#!/bin/bash
#1. 判断参数个数
if [ $# -lt 1 ]
then
  echo Not Enough Arguement!
  exit;
fi
#2. 遍历集群所有机器
for host in hadoop01 hadoop02 hadoop03
do
  echo ====================  $host  ====================
  #3. 遍历所有目录，挨个发送
  for file in $@
  do
    #4 判断文件是否存在
    if [ -e $file ]
    then
      #5. 获取父目录
      pdir=$(cd -P $(dirname $file); pwd)
      #6. 获取当前文件的名称
      fname=$(basename $file)
      ssh $host "mkdir -p $pdir"
      rsync -av $pdir/$fname $host:$pdir
    else
      echo $file does not exists!
    fi
  done
done
```

修改脚本 xsync 具有执行权限

`chmod +x xsync`

#### （10）免密登录配置

+ 生成公钥和私钥：

`ssh-keygen -t rsa`

​	 然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）

+ 将公钥拷贝到要免密登录的目标机器上

  ```sh
  ssh-copy-id hadoop01
  
  ssh-copy-id hadoop02
  
  ssh-copy-id hadoop03
  ```

+ 用xsync脚本分发.ssh

`sudo xsync .ssh`

#### （11）时间同步

用一台服务器作为同步时间的节点，定时同步时间

##### 1）时间服务器(hadoop01)配置（必须root用户）

（1）在所有节点关闭ntp服务和自启动

```shell
sudo systemctl stop ntpd

sudo systemctl disable ntpd
```

（2）修改ntp配置文件

`vim /etc/ntp.conf`



```shell
#1.授权192.168.1.0-192.168.1.255网段上的所有机器可以从这台机器上查询和同步时间）
#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap
#修改为
restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap

#2.修改（集群在局域网中，不使用其他互联网上的时间）
server 0.centos.pool.ntp.org iburst
server 1.centos.pool.ntp.org iburst
server 2.centos.pool.ntp.org iburst
server 3.centos.pool.ntp.org iburst
#为
#server 0.centos.pool.ntp.org iburst
#server 1.centos.pool.ntp.org iburst
#server 2.centos.pool.ntp.org iburst
#server 3.centos.pool.ntp.org iburst


#3.添加（当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步）
server 127.127.1.0
fudge 127.127.1.0 stratum 10
```

（3）修改/etc/sysconfig/ntpd 文件

`vim /etc/sysconfig/ntpd`

增加内容如下（让硬件时间与系统时间一起同步）

```shell
SYNC_HWCLOCK=yes
```

（4）重新启动ntpd服务

`systemctl start ntpd`

（5）设置ntpd服务开机启动

`systemctl enable ntpd`

##### 2）其他机器(hadoop02/hadoop03)配置（必须root用户)

（1）在其他机器配置10分钟与时间服务器同步一次

`crontab -e`

编写定时任务如下：

```shell
#编写定时器同步时间， 意义：每十分钟与hadoop01 同步一次时间。需要在集群中其他的机器中都编写 

*/10 * * * * /usr/sbin/ntpdate hadoop01
```



## 2.安装软件

#### (1)安装JDK

`tar -zxvf jdk-8u212-linux-x64.tar.gz -C /opt/software/`

配置环境变量

```shell
export JAVA_HOME=/opt/software/jdk1.8.0_212
export PATH=$PATH:$JAVA_HOME/bin
```

`java -version 查看环境变量是否配置成功`

#### (2)安装Hadoop

`tar -zxvf hadoop-3.1.3.tar.gz -C /opt/software/`

配置环境变量

```shell
export HADOOP_HOME=/opt/module/hadoop-3.1.3
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
```

`hadoop version 查看环境变量是否配置成功`

#### (3)同步集群

```shell
xsync /opt/software/hadoop-3.1.3
xsync /opt/software/jdk1.8.0_212
xsync /etc/profile.d/
```



## 3.集群配置

#### core配置文件

配置core-site.xml

`cd $HADOOP_HOME/etc/hadoop`

`vim core-site.xml`

文件内容如下：

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://hadoop01:8020</value>
  </property>
  <property>
   <name>hadoop.data.dir</name>
   <value>/opt/module/hadoop-3.1.3/data</value>
  </property>
  <property>
    <name>hadoop.proxyuser.bigdata.hosts</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.bigdata.groups</name>
    <value>*</value>
  </property>
</configuration>
```

#### HDFS配置文件

配置hdfs-site.xml

`vim hdfs-site.xml`

文件内容如下：

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
 <property>
  <name>dfs.namenode.name.dir</name>
  <value>file://${hadoop.data.dir}/name</value>
 </property>
 <property>
  <name>dfs.datanode.data.dir</name>
  <value>file://${hadoop.data.dir}/data</value>
 </property>
  <property>
  <name>dfs.namenode.checkpoint.dir</name>
  <value>file://${hadoop.data.dir}/namesecondary</value>
 </property>
 <property>
  <name>dfs.client.datanode-restart.timeout</name>
  <value>30</value>
 </property>
 <property>
  <name>dfs.namenode.secondary.http-address</name>
  <value>hadoop03:9868</value>
 </property>
</configuration>
```

#### YARN配置文件

配置yarn-site.xml

`vim yarn-site.xml`

文件内容如下：

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>mapreduce_shuffle</value>
  </property>
  <property>
    <name>yarn.resourcemanager.hostname</name>
    <value>hadoop02</value>
  </property>
  <property>
    <name>yarn.nodemanager.env-whitelist</name>     		<value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
  </property>
</configuration>
```

#### MapReduce配置文件

配置mapred-site.xml

`vim mapred-site.xml`

文件内容如下：

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
 <property>
  <name>mapreduce.framework.name</name>
  <value>yarn</value>
 </property>
    <!-- 历史服务器端地址 -->
 <property>
   <name>mapreduce.jobhistory.address</name>
   <value>hadoop01:10020</value>
 </property>
	<!-- 历史服务器web端地址 -->
 <property>
   <name>mapreduce.jobhistory.webapp.address</name>
   <value>hadoop01:19888</value>
 </property>
</configuration>
```

#### 同步集群

```
xsync /etc/hadoop-3.1.3/etc
```



## 4.启动集群

```SHELL
#整体启动HDFS
start-dfs.sh
#停止HDFS
stop-dfs.sh

#整体启动YARN
start-yarn.sh
#停止YARN
stop-yarn.sh

#历史服务器启动
mapred --daemon start historyserver
```

执行命令后浏览器查看

HDFS界面

http://hadoop01:9870/

![](https://shijin-img.oss-cn-chengdu.aliyuncs.com/blog-img/hdfs-web.png)

历史服务器界面

http://hadoop01:19888/jobhistory

![](https://shijin-img.oss-cn-chengdu.aliyuncs.com/blog-img/jobhistroy-web.png)